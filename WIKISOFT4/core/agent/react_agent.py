"""
ReACT Agent: Think â†’ Act â†’ Observe ë£¨í”„ ê¸°ë°˜ ììœ¨ì  ì˜ì‚¬ê²°ì •

ReACT (Reasoning and Acting) íŒ¨í„´:
1. Think: í˜„ì¬ ìƒí™© ë¶„ì„, ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
2. Act: ë„êµ¬ ì‹¤í–‰
3. Observe: ê²°ê³¼ ê´€ì°°, ì‹ ë¢°ë„ ì²´í¬
4. ë°˜ë³µ or ì¢…ë£Œ

íŠ¹ì§•:
- ììœ¨ì  ì¬ì‹œë„ (ì‹ ë¢°ë„ < ì„ê³„ê°’ì´ë©´ ë‹¤ë¥¸ ì „ëµ ì‹œë„)
- ì‚¬ëŒ ê°œì… ìš”ì²­ (í•´ê²° ë¶ˆê°€ëŠ¥í•˜ë©´ ì—ìŠ¤ì»¬ë ˆì´ì…˜)
- ì¶”ë¡  ê³¼ì • íˆ¬ëª…í•˜ê²Œ ê¸°ë¡
- LLM ê¸°ë°˜ ì¶”ë¡  (ì„ íƒì )
"""

import json
import os
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass, field
from enum import Enum


class AgentAction(Enum):
    """ì—ì´ì „íŠ¸ ì•¡ì…˜ íƒ€ì…."""
    PARSE = "parse_roster"
    MATCH = "match_headers"
    VALIDATE = "validate"
    REPORT = "generate_report"
    ASK_HUMAN = "ask_human"
    COMPLETE = "complete"
    FAIL = "fail"


@dataclass
class Thought:
    """ì—ì´ì „íŠ¸ì˜ ì‚¬ê³  ê³¼ì •."""
    step: int
    reasoning: str
    action: AgentAction
    action_params: Dict[str, Any] = field(default_factory=dict)
    confidence: float = 0.0


@dataclass
class Observation:
    """ì•¡ì…˜ ì‹¤í–‰ ê²°ê³¼."""
    action: AgentAction
    success: bool
    result: Any
    confidence: float = 0.0
    error: Optional[str] = None


@dataclass
class AgentState:
    """ì—ì´ì „íŠ¸ ìƒíƒœ."""
    thoughts: List[Thought] = field(default_factory=list)
    observations: List[Observation] = field(default_factory=list)
    current_step: int = 0
    status: str = "running"  # running, completed, failed, needs_human
    final_result: Optional[Dict[str, Any]] = None
    
    def add_thought(self, thought: Thought):
        self.thoughts.append(thought)
        self.current_step = thought.step
    
    def add_observation(self, observation: Observation):
        self.observations.append(observation)
    
    def get_history(self) -> List[Dict[str, Any]]:
        """ì¶”ë¡  ê³¼ì • íˆìŠ¤í† ë¦¬."""
        history = []
        for t, o in zip(self.thoughts, self.observations):
            history.append({
                "step": t.step,
                "thought": t.reasoning,
                "action": t.action.value,
                "result_success": o.success,
                "confidence": o.confidence,
                "error": o.error,
            })
        return history


class ReactAgent:
    """
    ReACT ê¸°ë°˜ ììœ¨ ì—ì´ì „íŠ¸.
    
    íŠ¹ì§•:
    - Tool Registryì—ì„œ ë„êµ¬ ì„ íƒ
    - ì‹ ë¢°ë„ ê¸°ë°˜ ì˜ì‚¬ê²°ì •
    - ìë™ ì¬ì‹œë„ (ìµœëŒ€ NíšŒ)
    - ì‚¬ëŒ ê°œì… ì—ìŠ¤ì»¬ë ˆì´ì…˜
    """
    
    # ì‹ ë¢°ë„ ì„ê³„ê°’
    CONFIDENCE_AUTO_COMPLETE = 0.95  # ì´ìƒì´ë©´ ìë™ ì™„ë£Œ
    CONFIDENCE_AUTO_CORRECT = 0.80   # ì´ìƒì´ë©´ ìë™ ìˆ˜ì • + ì•Œë¦¼
    CONFIDENCE_NEEDS_REVIEW = 0.50   # ë¯¸ë§Œì´ë©´ ì‚¬ëŒ ê²€í†  í•„ìš”
    
    def __init__(
        self,
        tool_registry,
        llm_client: Optional[Callable] = None,
        max_iterations: int = 5,
        verbose: bool = True,
        use_llm_reasoning: bool = True  # LLM ì¶”ë¡  í™œì„±í™” ì—¬ë¶€
    ):
        self.registry = tool_registry
        self.llm = llm_client
        self.max_iterations = max_iterations
        self.verbose = verbose
        self.use_llm_reasoning = use_llm_reasoning and self._has_openai_key()
        self.state = AgentState()
        self.retry_count = 0  # ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì 
    
    def _has_openai_key(self) -> bool:
        """OpenAI API í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸."""
        return bool(os.getenv("OPENAI_API_KEY"))
    
    def run(
        self,
        file_bytes: bytes,
        diagnostic_answers: Optional[Dict[str, Any]] = None,
        sheet_type: str = "ì¬ì§ì"
    ) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ ì‹¤í–‰: íŒŒì¼ â†’ ê²€ì¦ ê²°ê³¼.
        
        Args:
            file_bytes: ì—…ë¡œë“œëœ íŒŒì¼
            diagnostic_answers: ì§„ë‹¨ ì§ˆë¬¸ ë‹µë³€
            sheet_type: ì‹œíŠ¸ íƒ€ì…
        
        Returns:
            ìµœì¢… ê²€ì¦ ê²°ê³¼ + ì—ì´ì „íŠ¸ ì¶”ë¡  íˆìŠ¤í† ë¦¬
        """
        self.state = AgentState()
        context = {
            "file_bytes": file_bytes,
            "diagnostic_answers": diagnostic_answers or {},
            "sheet_type": sheet_type,
            "parsed": None,
            "matches": None,
            "validation": None,
        }
        
        for i in range(self.max_iterations):
            # 1. Think: ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
            thought = self._think(context, i + 1)
            self.state.add_thought(thought)
            
            if self.verbose:
                print(f"[Step {i+1}] Think: {thought.reasoning}")
                print(f"         Action: {thought.action.value}")
            
            # 2. ì¢…ë£Œ ì¡°ê±´ ì²´í¬
            if thought.action == AgentAction.COMPLETE:
                self.state.status = "completed"
                break
            elif thought.action == AgentAction.FAIL:
                self.state.status = "failed"
                break
            elif thought.action == AgentAction.ASK_HUMAN:
                self.state.status = "needs_human"
                break
            
            # 3. Act: ë„êµ¬ ì‹¤í–‰
            observation = self._act(thought, context)
            self.state.add_observation(observation)
            
            if self.verbose:
                print(f"         Result: {'âœ…' if observation.success else 'âŒ'} (conf: {observation.confidence:.2f})")
            
            # 4. Observe: ê²°ê³¼ ì—…ë°ì´íŠ¸
            self._observe(observation, context, thought.action)
            
            # 5. ì¡°ê¸° ì¢…ë£Œ ì²´í¬
            if observation.success and observation.confidence >= self.CONFIDENCE_AUTO_COMPLETE:
                if context.get("validation"):
                    self.state.status = "completed"
                    break
        
        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        return self._build_final_result(context)
    
    def _think(self, context: Dict[str, Any], step: int) -> Thought:
        """
        í˜„ì¬ ìƒí™© ë¶„ì„ ë° ë‹¤ìŒ ì•¡ì…˜ ê²°ì •.
        
        ê·œì¹™ ê¸°ë°˜ + LLM ì¶”ë¡  (API í‚¤ ìˆì„ ë•Œ).
        """
        # ìƒíƒœì— ë”°ë¥¸ ê·œì¹™ ê¸°ë°˜ ê²°ì •
        if context["parsed"] is None:
            return Thought(
                step=step,
                reasoning="íŒŒì¼ì´ íŒŒì‹±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì‹±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                action=AgentAction.PARSE,
                action_params={"file_bytes": context["file_bytes"]},
            )
        
        if context["matches"] is None:
            return Thought(
                step=step,
                reasoning="í—¤ë” ë§¤ì¹­ì´ í•„ìš”í•©ë‹ˆë‹¤. í‘œì¤€ ìŠ¤í‚¤ë§ˆì— ë§¤ì¹­í•©ë‹ˆë‹¤.",
                action=AgentAction.MATCH,
                action_params={
                    "parsed": context["parsed"],
                    "sheet_type": context["sheet_type"],
                },
            )
        
        # ë§¤ì¹­ ì‹ ë¢°ë„ ì²´í¬ + LLM ì¶”ë¡ 
        match_confidence = self._calculate_match_confidence(context["matches"])
        
        # ì‹ ë¢°ë„ê°€ ë‚®ê³  ì¬ì‹œë„ ê°€ëŠ¥í•˜ë©´ ì¬ì‹œë„
        if match_confidence < self.CONFIDENCE_AUTO_CORRECT and self.retry_count < 2:
            self.retry_count += 1
            reasoning = self._get_llm_reasoning(context, match_confidence) if self.use_llm_reasoning else \
                f"ë§¤ì¹­ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({match_confidence:.2f}). ì¬ì‹œë„í•©ë‹ˆë‹¤. (ì‹œë„ {self.retry_count}/2)"
            
            return Thought(
                step=step,
                reasoning=reasoning,
                action=AgentAction.MATCH,
                action_params={
                    "parsed": context["parsed"],
                    "sheet_type": context["sheet_type"],
                    "retry": True,  # ì¬ì‹œë„ í”Œë˜ê·¸
                },
                confidence=match_confidence,
            )
        
        if match_confidence < self.CONFIDENCE_NEEDS_REVIEW:
            reasoning = self._get_llm_reasoning(context, match_confidence) if self.use_llm_reasoning else \
                f"ë§¤ì¹­ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({match_confidence:.2f}). ì‚¬ëŒì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            
            return Thought(
                step=step,
                reasoning=reasoning,
                action=AgentAction.ASK_HUMAN,
                action_params={"reason": "low_match_confidence", "confidence": match_confidence},
                confidence=match_confidence,
            )
        
        if context["validation"] is None:
            return Thought(
                step=step,
                reasoning="ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                action=AgentAction.VALIDATE,
                action_params={
                    "parsed": context["parsed"],
                    "matches": context["matches"],
                    "diagnostic_answers": context["diagnostic_answers"],
                },
            )
        
        # ê²€ì¦ ì™„ë£Œ, ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return Thought(
            step=step,
            reasoning="ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
            action=AgentAction.COMPLETE,
            confidence=self._calculate_overall_confidence(context),
        )
    
    def _get_llm_reasoning(self, context: Dict[str, Any], confidence: float) -> str:
        """LLMì„ ì‚¬ìš©í•´ í˜„ì¬ ìƒí™© ë¶„ì„ ë° ì¶”ë¡ ."""
        if not self.use_llm_reasoning:
            return f"ì‹ ë¢°ë„: {confidence:.2f}"
        
        try:
            from openai import OpenAI
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            # í˜„ì¬ ìƒí™© ìš”ì•½
            matches = context.get("matches", {}).get("matches", [])
            unmapped = [m["source"] for m in matches if m.get("unmapped")]
            low_conf = [m["source"] for m in matches if m.get("confidence", 1) < 0.7 and not m.get("unmapped")]
            
            prompt = f"""ë‹¹ì‹ ì€ HR ë°ì´í„° ê²€ì¦ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. í˜„ì¬ ìƒí™©ì„ ë¶„ì„í•˜ì„¸ìš”.

í˜„ì¬ ìƒí™©:
- ë§¤ì¹­ ì‹ ë¢°ë„: {confidence:.2f}
- ë¯¸ë§¤í•‘ í—¤ë”: {unmapped[:5]}
- ë‚®ì€ ì‹ ë¢°ë„ í—¤ë”: {low_conf[:5]}
- ì¬ì‹œë„ íšŸìˆ˜: {self.retry_count}/2

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê³  ì´ìœ ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”:
1. ì¬ì‹œë„ (ë‹¤ë¥¸ ì „ëµìœ¼ë¡œ ë§¤ì¹­ ì‹œë„)
2. ì‚¬ëŒì—ê²Œ ì§ˆë¬¸ (ì–´ë–¤ í—¤ë”ê°€ ì–´ë–¤ í•„ë“œì¸ì§€ í™•ì¸)
3. ì§„í–‰ (í˜„ì¬ ìƒíƒœë¡œ ê³„ì†)

ì‘ë‹µ í˜•ì‹: [ì„ íƒë²ˆí˜¸] ì´ìœ """

            response = client.chat.completions.create(
                model="gpt-4o-mini",  # ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.3,
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            return f"LLM ì¶”ë¡  ì‹¤íŒ¨: {e}. ê·œì¹™ ê¸°ë°˜ ê²°ì • ì‚¬ìš©."
    
    def _act(self, thought: Thought, context: Dict[str, Any]) -> Observation:
        """ë„êµ¬ ì‹¤í–‰."""
        try:
            if thought.action == AgentAction.PARSE:
                result = self.registry.call_tool("parse_roster", **thought.action_params)
                return Observation(
                    action=thought.action,
                    success=bool(result.get("headers")),
                    result=result,
                    confidence=1.0 if result.get("headers") else 0.0,
                )
            
            elif thought.action == AgentAction.MATCH:
                result = self.registry.call_tool("match_headers", **thought.action_params)
                confidence = self._calculate_match_confidence(result)
                return Observation(
                    action=thought.action,
                    success=True,
                    result=result,
                    confidence=confidence,
                )
            
            elif thought.action == AgentAction.VALIDATE:
                result = self.registry.call_tool("validate", **thought.action_params)
                confidence = self._calculate_validation_confidence(result)
                return Observation(
                    action=thought.action,
                    success=result.get("passed", False),
                    result=result,
                    confidence=confidence,
                )
            
            else:
                return Observation(
                    action=thought.action,
                    success=False,
                    result=None,
                    error=f"Unknown action: {thought.action}",
                )
        
        except Exception as e:
            return Observation(
                action=thought.action,
                success=False,
                result=None,
                error=str(e),
                confidence=0.0,
            )
    
    def _observe(self, observation: Observation, context: Dict[str, Any], action: AgentAction):
        """ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ë°˜ì˜."""
        if not observation.success:
            return
        
        if action == AgentAction.PARSE:
            context["parsed"] = observation.result
        elif action == AgentAction.MATCH:
            context["matches"] = observation.result
        elif action == AgentAction.VALIDATE:
            context["validation"] = observation.result
    
    def _calculate_match_confidence(self, matches: Dict[str, Any]) -> float:
        """ë§¤ì¹­ ì‹ ë¢°ë„ ê³„ì‚°."""
        if matches is None:
            return 0.0
        
        match_list = matches.get("matches", [])
        if not match_list:
            return 0.0
        
        total_conf = sum(m.get("confidence", 0) for m in match_list)
        avg_conf = total_conf / len(match_list)
        
        # unmapped íŒ¨ë„í‹°
        unmapped_count = sum(1 for m in match_list if m.get("unmapped"))
        unmapped_penalty = unmapped_count * 0.05
        
        return max(0.0, min(1.0, avg_conf - unmapped_penalty))
    
    def _calculate_validation_confidence(self, validation: Dict[str, Any]) -> float:
        """ê²€ì¦ ì‹ ë¢°ë„ ê³„ì‚°."""
        if validation is None:
            return 0.0
        
        if validation.get("passed"):
            return 1.0
        
        errors = len(validation.get("errors", []))
        warnings = len(validation.get("warnings", []))
        
        confidence = 1.0 - (errors * 0.1) - (warnings * 0.05)
        return max(0.0, min(1.0, confidence))
    
    def _calculate_overall_confidence(self, context: Dict[str, Any]) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°."""
        match_conf = self._calculate_match_confidence(context.get("matches", {}))
        val_conf = self._calculate_validation_confidence(context.get("validation", {}))
        
        # ê°€ì¤‘ í‰ê· 
        return (match_conf * 0.4) + (val_conf * 0.6)
    
    def _build_final_result(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±."""
        overall_confidence = self._calculate_overall_confidence(context)
        
        # ì‹ ë¢°ë„ ë“±ê¸‰
        if overall_confidence >= self.CONFIDENCE_AUTO_COMPLETE:
            grade = "A"
            recommendation = "auto_complete"
        elif overall_confidence >= self.CONFIDENCE_AUTO_CORRECT:
            grade = "B"
            recommendation = "auto_correct_with_review"
        elif overall_confidence >= self.CONFIDENCE_NEEDS_REVIEW:
            grade = "C"
            recommendation = "manual_review"
        else:
            grade = "D"
            recommendation = "full_manual_review"
        
        return {
            "status": self.state.status,
            "confidence": {
                "score": overall_confidence,
                "grade": grade,
                "recommendation": recommendation,
            },
            "steps": {
                "parsed_summary": {
                    "headers": (context.get("parsed") or {}).get("headers", []),
                    "row_count": len((context.get("parsed") or {}).get("rows", [])),
                },
                "matches": context.get("matches"),
                "validation": context.get("validation"),
            },
            "agent_reasoning": self.state.get_history(),
            "iterations": self.state.current_step,
            "needs_human_review": self.state.status == "needs_human",
        }
    
    def explain_reasoning(self) -> str:
        """ì¶”ë¡  ê³¼ì • ì„¤ëª… (ì‚¬ìš©ììš©)."""
        lines = ["ğŸ¤– AI ì—ì´ì „íŠ¸ ì¶”ë¡  ê³¼ì •:\n"]
        
        for thought in self.state.thoughts:
            status = "â³"
            if thought.action == AgentAction.COMPLETE:
                status = "âœ…"
            elif thought.action == AgentAction.FAIL:
                status = "âŒ"
            elif thought.action == AgentAction.ASK_HUMAN:
                status = "ğŸ™‹"
            
            lines.append(f"{status} Step {thought.step}: {thought.reasoning}")
        
        return "\n".join(lines)


def create_react_agent(tool_registry, llm_client=None, verbose: bool = False) -> ReactAgent:
    """ReACT ì—ì´ì „íŠ¸ ìƒì„±."""
    return ReactAgent(
        tool_registry=tool_registry,
        llm_client=llm_client,
        max_iterations=5,
        verbose=verbose,
    )
