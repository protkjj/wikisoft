# ğŸ¤– WIKISOFT2 AI Agent ììœ¨í™” ë¡œë“œë§µ

**ë²„ì „**: 1.0  
**ì‘ì„±ì¼**: 2025-12-26  
**ìµœì¢… ëª©í‘œ**: ì™„ì „ììœ¨ AI Agent (v4.0, 2025ë…„ Q3)

---

## ğŸ“Š Executive Summary

### í˜„ì¬ ìƒíƒœ (v2.1)
- **ì‚¬ëŒ ê°œì…**: ~100% (ëª¨ë“  ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€)
- **ì²˜ë¦¬ ì‹œê°„**: 30-60ë¶„/íŒŒì¼
- **ì‹ ë¢°ë„**: ~70% (í´ë°± í¬í•¨)
- **í™•ì¥ì„±**: ì„ í˜• (ê²½í—˜ ì¦ê°€ ì•ˆ í•¨)

### ëª©í‘œ ìƒíƒœ (v4.0)
- **ì‚¬ëŒ ê°œì…**: ~5% (ì˜ˆì™¸ë§Œ)
- **ì²˜ë¦¬ ì‹œê°„**: 1ë¶„/íŒŒì¼ (**60ë°° ë¹ ë¦„**)
- **ì‹ ë¢°ë„**: 95%+ (ì „ë¬¸ê°€ ìˆ˜ì¤€)
- **í™•ì¥ì„±**: ì´ˆì„ í˜• (ê²½í—˜ìœ¼ë¡œ ì„±ëŠ¥ ì¦ê°€)

---

## ğŸ¯ Phaseë³„ ê³„íš

### **Phase 1: Foundation (2ì£¼, v2.2)**

#### ëª©í‘œ
- Tool Registry êµ¬ì¶•
- ReACT Loop ê¸°ì´ˆ
- Confidence ëª¨ë¸
- Decision Engine

#### ìƒì„¸ ì‘ì—…

**1. Tool Registry (ë„êµ¬ ì¤‘ì•™ ê´€ë¦¬)**
```python
# internal/tools/registry.py
class ToolRegistry:
    """
    ëª¨ë“  Agentê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ ì¤‘ì•™ ê´€ë¦¬
    """
    
    def __init__(self):
        self.tools = {
            "parse_excel": ParseExcelTool(),
            "validate_data": ValidateDataTool(),
            "detect_anomalies": AnomalyDetectorTool(),
            "auto_correct": AutoCorrectTool(),
            "estimate_confidence": ConfidenceTool(),
            "generate_report": ReportGeneratorTool(),
        }
    
    def call(self, tool_name: str, **kwargs):
        """ë„êµ¬ ì‹¤í–‰"""
        return self.tools[tool_name].execute(**kwargs)
    
    def describe(self):
        """Agentê°€ ì‚¬ìš©í•  ë„êµ¬ ì„¤ëª… (LLM í”„ë¡¬í”„íŠ¸ìš©)"""
        return {
            tool_name: tool.description
            for tool_name, tool in self.tools.items()
        }
```

**2. ReACT Loop (Reasoning + Acting)**
```python
# internal/agent/react_loop.py
async def react_loop(file_path: str, max_steps: int = 10):
    """
    Agentì˜ ì‚¬ê³ ê³¼ì • + í–‰ë™ ë£¨í”„
    
    1. THOUGHT: LLMì´ ìƒí™© ë¶„ì„
    2. ACTION: ë‹¤ìŒ ë„êµ¬ ì„ íƒ
    3. OBSERVATION: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
    4. ë°˜ë³µ
    """
    state = AgentState(file_path)
    
    for step in range(max_steps):
        # 1ï¸âƒ£ THOUGHT
        thought = await llm.think(state)
        
        # 2ï¸âƒ£ ACTION (LLMì´ ë„êµ¬ ì„ íƒ)
        action = extract_action(thought)
        
        # 3ï¸âƒ£ OBSERVATION
        result = await tool_registry.call(action.name, **action.params)
        state.add_observation(result)
        
        # 4ï¸âƒ£ ì™„ë£Œ í™•ì¸
        if state.is_complete():
            break
    
    return state.generate_report()
```

**3. Confidence Scorer (ì‹ ë¢°ë„ ê³„ì‚°)**
```python
# internal/agent/confidence.py
class ConfidenceScorer:
    """ì‹ ë¢°ë„ ê¸°ë°˜ ì˜ì‚¬ê²°ì •"""
    
    def score(self, state: Dict) -> float:
        """
        ì¢…í•© ì‹ ë¢°ë„ = 
            30% Ã— ë°ì´í„°_í’ˆì§ˆ +
            25% Ã— ê²€ì¦_ê·œì¹™ +
            20% Ã— ìˆ˜ì •_ì•ˆì •ì„± +
            15% Ã— ì‚¬ë¡€_ìœ ì‚¬ë„ +
            10% Ã— ëª¨ë¸_ì‹ ë¢°ë„
        """
        return (
            0.30 * self.data_quality(state) +
            0.25 * self.rule_match(state) +
            0.20 * self.fix_stability(state) +
            0.15 * self.case_similarity(state) +
            0.10 * self.model_confidence(state)
        )
    
    def decide(self, confidence: float) -> str:
        """ì‹ ë¢°ë„ì— ë”°ë¥¸ ì•¡ì…˜ ê²°ì •"""
        if confidence >= 0.95:
            return "AUTO_COMPLETE"
        elif confidence >= 0.80:
            return "AUTO_CORRECT"
        elif confidence >= 0.70:
            return "AUTO_WITH_REVIEW"
        else:
            return "ASK_HUMAN"
```

**4. Decision Engine (ìë™ ì˜ì‚¬ê²°ì •)**
```python
# internal/agent/decision_engine.py
class DecisionEngine:
    """Agentê°€ ë§¤ ë‹¨ê³„ë§ˆë‹¤ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •"""
    
    def decide(self, state: Dict) -> Action:
        confidence = self.scorer.score(state)
        action_type = self.scorer.decide(confidence)
        
        if action_type == "AUTO_COMPLETE":
            return Action(type='complete')
        elif action_type == "AUTO_CORRECT":
            return Action(
                type='auto_fix',
                strategy='optimistic',
                notify=False
            )
        elif action_type == "AUTO_WITH_REVIEW":
            return Action(
                type='auto_fix',
                strategy='conservative',
                notify=True
            )
        else:
            return Action(
                type='ask_human',
                question=self.formulate_question(state)
            )
```

#### ê²°ê³¼ë¬¼
- âœ… `internal/tools/registry.py` (ë„êµ¬ ê´€ë¦¬)
- âœ… `internal/agent/react_loop.py` (ìë™í™” ë£¨í”„)
- âœ… `internal/agent/confidence.py` (ì‹ ë¢°ë„)
- âœ… `internal/agent/decision_engine.py` (ì˜ì‚¬ê²°ì •)
- âœ… `POST /auto-validate` (ìƒˆ API)

#### ì„±ê³¼
```
ë°˜ììœ¨ Agent
- ìë™í™”ìœ¨: 20-30%
- ì‚¬ëŒ ê°œì…: 70-80%
- ì²˜ë¦¬ ì‹œê°„: 20-30ë¶„/íŒŒì¼
```

---

### **Phase 2: Intelligence (2ê°œì›”, v3.0)**

#### ëª©í‘œ
- LangChain/LlamaIndex í†µí•©
- Memory ì‹œìŠ¤í…œ (Redis + Vector DB)
- Few-shot learning
- Human-in-the-loop UI

#### ìƒì„¸ ì‘ì—…

**1. LangChain í†µí•©**
```python
# internal/agent/langchain_agent.py
from langchain.agents import initialize_agent
from langchain.tools import Tool

class WIKISoftLangChainAgent:
    def __init__(self):
        self.agent = initialize_agent(
            tools=[...],
            llm=ChatOpenAI(model="gpt-4"),
            agent="zero-shot-react-description"
        )
```

**2. Memory ì‹œìŠ¤í…œ**
```python
# internal/agent/memory.py
class AgentMemory:
    """Agentì˜ í•™ìŠµ ê¸°ì–µì†Œ"""
    
    def __init__(self):
        self.short_term = Redis()  # í˜„ì¬ ì‘ì—…
        self.long_term = Chroma()  # í•™ìŠµí•œ íŒ¨í„´
        self.audit_log = PostgreSQL()  # ëª¨ë“  ì˜ì‚¬ê²°ì •
    
    def learn_pattern(self, pattern: Dict):
        """ê³¼ê±° ì¼€ì´ìŠ¤ë¡œë¶€í„° í•™ìŠµ"""
        embedding = self.embed(pattern)
        self.long_term.add(pattern, embedding)
    
    def retrieve_similar(self, context: Dict):
        """ìœ ì‚¬í•œ ê³¼ê±° ì‚¬ë¡€ ì¡°íšŒ"""
        return self.long_term.search(self.embed(context), top_k=5)
```

**3. Few-shot Learning**
```python
# ìƒí™©ë³„ í”„ë¡¬í”„íŠ¸ ìµœì í™”
# ì˜ˆ: "ì„ì› ì¸ì› ìˆ˜ì •" íŒ¨í„´ì„ ë³¸ ì  ìˆìœ¼ë©´
#     ìƒˆë¡œìš´ "ì„ì› ì¸ì›" ë¬¸ì œëŠ” ë¹ ë¥´ê²Œ í•´ê²°

FEWSHOT_EXAMPLES = {
    "employee_count_anomaly": [
        {"input": ..., "reasoning": ..., "action": ...},
        {"input": ..., "reasoning": ..., "action": ...},
        ...
    ],
    "salary_distribution_anomaly": [...],
    ...
}
```

**4. Human-in-the-Loop UI**
```typescript
// frontend/src/components/HumanReview.tsx
<HumanReviewPanel>
  <Question
    id="q21"
    title="ì„ì› ì¸ì› ìˆ˜ì • í™•ì¸"
    description="ìë™ìœ¼ë¡œ 17ëª…ìœ¼ë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤"
    options={["ìŠ¹ì¸", "ê±°ì ˆ", "ìˆ˜ë™ ì…ë ¥"]}
    confidence={0.87}
    riskLevel="medium"
  />
</HumanReviewPanel>
```

#### ê²°ê³¼ë¬¼
- âœ… `internal/agent/langchain_agent.py`
- âœ… `internal/agent/memory.py`
- âœ… `internal/tools/few_shot_examples.json`
- âœ… Human-in-the-loop UI (React)
- âœ… `POST /batch-validate` (ë°°ì¹˜ API)

#### ì„±ê³¼
```
ì¤€ììœ¨ Agent
- ìë™í™”ìœ¨: 85-90%
- ì‚¬ëŒ ê°œì…: 10-15%
- ì²˜ë¦¬ ì‹œê°„: 5-10ë¶„/íŒŒì¼ (3ë°° ë¹ ë¦„)
- ì‹ ë¢°ë„: 85%+
```

---

### **Phase 3: Autonomy (3ê°œì›”, v4.0)**

#### ëª©í‘œ
- ì™„ì „ìë™í™” (5% ì´í•˜ ê°œì…)
- Cross-file í•™ìŠµ
- ìì²´ ê²€ì¦
- Batch ì²˜ë¦¬ (ëŒ€ëŸ‰ íŒŒì¼)

#### ìƒì„¸ ì‘ì—…

**1. ìë™ ë¦¬í”Œë˜ë‹**
```python
# ì‹¤íŒ¨ ì‹œ ì „ëµ ë³€ê²½
if task_failed:
    # ë‹¤ë¥¸ ë„êµ¬ ì¡°í•© ì‹œë„
    new_plan = await agent.replan(state, failed_action)
    # ì˜ˆ: auto_correct ì‹¤íŒ¨ â†’ ask_human
```

**2. Cross-File Learning**
```python
# ì—¬ëŸ¬ íŒŒì¼ ê²½í—˜ìœ¼ë¡œ í•™ìŠµ
# 100ê°œ íŒŒì¼ ì²˜ë¦¬ í›„, ìƒˆë¡œìš´ ìœ ì‚¬ íŒŒì¼ì€ ê±°ì˜ ìë™
patterns_learned = 0
for file in files:
    result = await agent.process(file)
    patterns_learned += result.num_new_patterns
    
    if patterns_learned > 50:
        confidence += 0.15  # ì‹ ë¢°ë„ ì¦ê°€
```

**3. ìì²´ ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜**
```python
# Agentê°€ ìì‹ ì˜ ê²°ì •ì„ ê²€ì¦
result = await agent.auto_fix()
# ë‹¤ì‹œ ê²€ì¦í•´ì„œ ë§ëŠ”ì§€ í™•ì¸
validation = await validator.validate(result)

if validation.score > 0.95:
    # ì‹ ë¢°ë„ ë†’ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
    return result
else:
    # ë‚®ìœ¼ë©´ ì‚¬ëŒì—ê²Œ ë¬¸ì˜
    return await ask_human()
```

**4. Batch Processing**
```python
# ëŒ€ëŸ‰ íŒŒì¼ ìë™ ì²˜ë¦¬
POST /batch-validate
[
    file1.xlsx, file2.xlsx, ..., file1000.xlsx
]

# Agentê°€ ë³‘ë ¬ë¡œ ì²˜ë¦¬ (ë™ì‹œì„± ê´€ë¦¬)
# ì‹ ë¢°ë„ ë†’ì€ ê²ƒë¶€í„° ìë™ ì™„ë£Œ
# ì‹ ë¢°ë„ ë‚®ì€ ê²ƒë§Œ ëŒ€ê¸°ì—´ì— (ì‚¬ëŒì´ ì²˜ë¦¬)
```

#### ê²°ê³¼ë¬¼
- âœ… `internal/agent/replanning.py`
- âœ… `internal/agent/cross_file_learning.py`
- âœ… `internal/agent/self_validation.py`
- âœ… Batch processing engine
- âœ… Admin dashboard

#### ì„±ê³¼
```
ì™„ì „ììœ¨ Agent
- ìë™í™”ìœ¨: 95%+
- ì‚¬ëŒ ê°œì…: <5% (ì˜ˆì™¸ë§Œ)
- ì²˜ë¦¬ ì‹œê°„: 1ë¶„/íŒŒì¼ (60ë°° ë¹ ë¦„)
- ì‹ ë¢°ë„: 95%+
- ëŒ€ëŸ‰ ì²˜ë¦¬: 1000+íŒŒì¼/ì¼
```

---

## ğŸ”„ ë§ˆì¼ìŠ¤í†¤ & ì¼ì •

### Timeline
```
Week 1-2    â”‚ Phase 1: Tool Registry + ReACT Loop
            â”‚ ğŸ’¾ v2.2 ë¦´ë¦¬ì¦ˆ
            â”‚
Week 3-4    â”‚ Phase 2 ì‹œì‘: LangChain, Memory
            â”‚
Month 2     â”‚ Phase 2 ë§ˆë¬´ë¦¬: Few-shot, UI
            â”‚ ğŸ’¾ v3.0 ë² íƒ€ ë¦´ë¦¬ì¦ˆ
            â”‚
Month 3     â”‚ Phase 3: ë¦¬í”Œë˜ë‹, Cross-file í•™ìŠµ
            â”‚
Month 4     â”‚ Phase 3 ë§ˆë¬´ë¦¬: ì™„ì „ìë™í™”
            â”‚ ğŸ’¾ v4.0 ì •ì‹ ë¦´ë¦¬ì¦ˆ
```

### ë¦´ë¦¬ì¦ˆ ë²„ì „
```
v2.1 (í˜„ì¬)     ê¸°ë³¸ ê²€ì¦ ì‹œìŠ¤í…œ
v2.2 (2ì£¼)      Tool Registry + ReACT (ë°˜ììœ¨ Agent)
v3.0 (2ê°œì›”)    Memory + í•™ìŠµ (ì¤€ììœ¨ Agent)
v4.0 (3ê°œì›”)    ì™„ì „ìë™í™” (ì™„ì „ììœ¨ Agent)
```

---

## ğŸ’° ë¹„ìš© vs íš¨ê³¼

### ê°œë°œ ë¹„ìš©
```
Phase 1: 80ì‹œê°„ (2ì£¼)
Phase 2: 160ì‹œê°„ (4ì£¼)
Phase 3: 200ì‹œê°„ (5ì£¼)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í•©ê³„: ~450ì‹œê°„ (ì•½ 3ê°œì›”)
```

### íš¨ê³¼ (ì—°ê°„)
```
ì²˜ë¦¬ ì‹œê°„ ì ˆê°
- í˜„ì¬: 30ë¶„/íŒŒì¼ Ã— 1000íŒŒì¼/ë…„ = 500ì‹œê°„/ë…„
- v4.0: 1ë¶„/íŒŒì¼ Ã— 1000íŒŒì¼/ë…„ = 17ì‹œê°„/ë…„
- ì ˆê°: 483ì‹œê°„/ë…„ (97% ê°ì†Œ)

ë¹„ìš© ì ˆê° (ì‹œê¸‰ $50 ê¸°ì¤€)
- ì ˆê°ì•¡: 483ì‹œê°„ Ã— $50 = $24,150/ë…„

ROI
- ê°œë°œ ë¹„ìš©: 450ì‹œê°„ Ã— $50 = $22,500
- ì—°ê°„ ì ˆê°: $24,150
- **Year 1 ROI: 107%** ğŸ¯
```

---

## âš ï¸ ë¦¬ìŠ¤í¬ & ëŒ€ì‘

### Risk 1: LLM API ë¹„ìš© ì¦ê°€
```
ë¬¸ì œ: Agent ë£¨í”„ì—ì„œ LLM í˜¸ì¶œ ë°˜ë³µ
ëŒ€ì‘:
- ìºì‹± (ë™ì¼ ì¿¼ë¦¬ëŠ” ì €ì¥ëœ ë‹µë³€ ì¬ì‚¬ìš©)
- ë°°ì¹˜ API (ì—¬ëŸ¬ ìš”ì²­ì„ í•œ ë²ˆì— ì²˜ë¦¬)
- ì €ë¹„ìš© ëª¨ë¸ ëŒ€ì²´ (GPT-4 â†’ GPT-3.5 í•„ìš”ì‹œ)
```

### Risk 2: ììœ¨í™” ì‹¤íŒ¨ (ì‹ ë¢°ë„ ë‚®ìŒ)
```
ë¬¸ì œ: ì˜ì™¸ë¡œ ì‹ ë¢°ë„ê°€ ì˜¬ë¼ê°€ì§€ ì•ŠëŠ” ê²½ìš°
ëŒ€ì‘:
- Few-shot learning ë°ì´í„° ì¶”ê°€
- í”„ë¡¬í”„íŠ¸ ì¬ì„¤ê³„
- ë„êµ¬ ì •í™•ë„ ê°œì„ 
- Fallback to ì‚¬ëŒ (ì‹¤íŒ¨ ì•ˆ í•¨)
```

### Risk 3: ë©”ëª¨ë¦¬ í­ë°œ (Vector DB í¬ê¸°)
```
ë¬¸ì œ: íŒ¨í„´ì´ ê³„ì† ìŒ“ì—¬ì„œ ê²€ìƒ‰ ëŠë ¤ì§
ëŒ€ì‘:
- ì •ê¸°ì  í´ëŸ¬ìŠ¤í„°ë§ (ë¹„ìŠ·í•œ íŒ¨í„´ í†µí•©)
- ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
- íš¨ìœ¨ì ì¸ ì¸ë±ì‹±
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1 ì™„ë£Œ ì¡°ê±´
- [ ] Tool Registry 100% ì»¤ë²„ë¦¬ì§€
- [ ] ReACT Loop ì‹¤í–‰ ì„±ê³µ
- [ ] Confidence ëª¨ë¸ ì •í™•ë„ 70%+
- [ ] `/auto-validate` API ë™ì‘
- [ ] Unit tests ì»¤ë²„ë¦¬ì§€ 70%+

### Phase 2 ì™„ë£Œ ì¡°ê±´
- [ ] LangChain í†µí•© ì™„ë£Œ
- [ ] Memory ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] Few-shot ì˜ˆì œ 50+ ìˆ˜ì§‘
- [ ] Human-in-the-loop UI ì™„ì„±
- [ ] ìë™í™”ìœ¨ 85%+ ë‹¬ì„±

### Phase 3 ì™„ë£Œ ì¡°ê±´
- [ ] ë¦¬í”Œë˜ë‹ ì•Œê³ ë¦¬ì¦˜ ì •í™•ë„ 90%+
- [ ] Cross-file í•™ìŠµ êµ¬í˜„
- [ ] ìì²´ ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜ ì‹ ë¢°ë„ 95%+
- [ ] Batch ì²˜ë¦¬ 1000íŒŒì¼/ì¼ ì²˜ë¦¬
- [ ] ìµœì¢… ìë™í™”ìœ¨ 95%+ ë‹¬ì„±

---

## ğŸš€ ì‹œì‘í•˜ê¸°

### ì¦‰ì‹œ í•  ì¼ (ì´ë²ˆ ì£¼)
```bash
# 1. í´ë” êµ¬ì¡° ì„¤ê³„
mkdir -p internal/{tools,agent}

# 2. Tool Registry ìŠ¤ì¼ˆë ˆí†¤
touch internal/tools/registry.py

# 3. ReACT Loop ìŠ¤ì¼ˆë ˆí†¤
touch internal/agent/react_loop.py

# 4. requirements.txt ì—…ë°ì´íŠ¸
pip install langchain chromadb redis
```

### ë‹¤ìŒ ì£¼
```bash
# 1. Tool Registry êµ¬í˜„
# 2. ReACT Loop êµ¬í˜„
# 3. Confidence Scorer êµ¬í˜„
# 4. í…ŒìŠ¤íŠ¸ ì‘ì„±
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [ReACT: Synergizing Reasoning and Acting](https://arxiv.org/abs/2210.03629)
- [LangChain Documentation](https://python.langchain.com/)
- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [Self-Consistency CoT](https://arxiv.org/abs/2203.11171)

---

**ìµœì¢… ëª©í‘œ**: ì™„ì „ììœ¨ AI Agent ë‹¬ì„± (2025ë…„ Q3)  
**í•µì‹¬ ê°€ì¹˜**: ì¸ê°„ì˜ ì°½ì˜ë ¥ + AIì˜ ìë™í™” ëŠ¥ë ¥ = ì´ˆì¸ì  ìƒì‚°ì„± ğŸš€
