import json
import logging
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, HTTPException, status
from pydantic import BaseModel

from internal.agent.tool_registry import get_registry
from internal.ai.diagnostic_questions import ALL_QUESTIONS
from internal.ai.knowledge_base import get_system_context
from internal.ai.llm_client import get_llm_client
from internal.ai.autonomous_learning import analyze_chat_for_learning

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/agent", tags=["agent"])


class AgentAskRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None


# íˆ´ ì •ì˜ (OpenAI function calling í˜•ì‹)
AGENT_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "list_diagnostic_questions",
            "description": "ì¬ì§ì ëª…ë¶€ ê²€ì¦ìš© 13ê°œ ì§„ë‹¨ ì§ˆë¬¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "list_available_tools",
            "description": "ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ì¦ ë„êµ¬ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤ (íŒŒì‹±, ë§¤ì¹­, ê²€ì¦, ë¦¬í¬íŠ¸ ìƒì„± ë“±).",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
]


def _execute_tool(tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
    """íˆ´ ì‹¤í–‰ í•¨ìˆ˜"""
    if tool_name == "list_diagnostic_questions":
        return {
            "total": len(ALL_QUESTIONS),
            "questions": [
                {"id": q["id"], "question": q["question"], "type": q["type"]}
                for q in ALL_QUESTIONS[:5]  # ì²˜ìŒ 5ê°œë§Œ ë°˜í™˜ (í† í° ì ˆì•½)
            ],
            "note": "ì´ 13ê°œ ì§ˆë¬¸ ì¤‘ ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ",
        }
    elif tool_name == "list_available_tools":
        registry = get_registry()
        return {"tools": registry.list_tools()}
    else:
        return {"error": f"Unknown tool: {tool_name}"}


def _build_messages(req: AgentAskRequest) -> List[Dict[str, str]]:
    # ì‹œìŠ¤í…œ ì§€ì‹ ë¡œë“œ
    knowledge = get_system_context(req.message)
    
    # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ íŒŒì¼ì´ ì´ë¯¸ ì—…ë¡œë“œëœ ìƒíƒœ
    has_context = req.context and req.context.get("has_file")
    
    context_info = ""
    if has_context and req.context.get("validation_results"):
        vr = req.context["validation_results"]
        
        # ë§¤ì¹­ ê²°ê³¼ ìš”ì•½
        matches = vr.get("steps", {}).get("matches", {}).get("matches", [])
        matched_fields = [m.get("target") for m in matches if m.get("target")]
        required_fields = ['ì‚¬ì›ë²ˆí˜¸', 'ìƒë…„ì›”ì¼', 'ì„±ë³„', 'ì…ì‚¬ì¼ì', 'ì¢…ì—…ì›êµ¬ë¶„', 'ê¸°ì¤€ê¸‰ì—¬']
        matched_required = [f for f in required_fields if f in matched_fields]
        missing_required = [f for f in required_fields if f not in matched_fields]
        
        # ê²€ì¦ ì˜¤ë¥˜/ê²½ê³  ìš”ì•½
        errors = vr.get("steps", {}).get("validation", {}).get("errors", [])
        warnings = vr.get("steps", {}).get("validation", {}).get("warnings", [])
        
        # ì‹ ë¢°ë„
        confidence = vr.get("confidence", {}).get("score", 0)
        
        context_info = f"""
=== í˜„ì¬ ê²€ì¦ ì™„ë£Œëœ íŒŒì¼ ìƒíƒœ ===
âœ… íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì–´ ê²€ì¦ ì™„ë£Œë¨

ğŸ“Š ì»¬ëŸ¼ ë§¤í•‘ ê²°ê³¼:
- ë§¤í•‘ëœ í•„ë“œ {len(matched_fields)}ê°œ: {', '.join(matched_fields)}
- í•„ìˆ˜ í•„ë“œ ë§¤í•‘: {', '.join(matched_required)} ({len(matched_required)}/{len(required_fields)}ê°œ ì™„ë£Œ)
- ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œ: {', '.join(missing_required) if missing_required else 'ì—†ìŒ (ëª¨ë‘ ë§¤í•‘ë¨)'}

ğŸ” ê²€ì¦ ê²°ê³¼:
- ì‹ ë¢°ë„: {confidence*100:.0f}%
- ì˜¤ë¥˜: {len(errors)}ê±´
- ê²½ê³ : {len(warnings)}ê±´
{('- ì˜¤ë¥˜ ë‚´ìš©: ' + ', '.join([e.get('message', '')[:50] for e in errors[:3]])) if errors else ''}
{('- ê²½ê³  ë‚´ìš©: ' + ', '.join([w.get('message', '')[:50] for w in warnings[:3]])) if warnings else ''}

âš ï¸ ì£¼ì˜: ìœ„ ì •ë³´ê°€ ì´ë¯¸ ê²€ì¦ëœ ê²°ê³¼ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ "íŒŒì¼ì„ ì œê³µí•´ì£¼ì„¸ìš”"ë¼ê³  í•˜ì§€ ë§ˆì„¸ìš”.
"""

    system_prompt = f"""You are the WIKISOFT3 validation co-pilot.
Help users validate HR/pension Excel files.
Use tools when needed. Be concise in Korean.

=== System Knowledge ===
{knowledge}

{context_info}

âš ï¸ ì¤‘ìš” ì§€ì¹¨:
1. ì‚¬ìš©ìê°€ ì´ë¯¸ íŒŒì¼ì„ ì—…ë¡œë“œí–ˆìœ¼ë©´ "íŒŒì¼ì„ ì œê³µí•´ ì£¼ì„¸ìš”" ê°™ì€ ë§ ê¸ˆì§€
2. ë‚ ì§œ/ìˆ«ì í˜•ì‹ì€ ì‹œìŠ¤í…œì´ ìë™ ë³€í™˜í•˜ë¯€ë¡œ "í˜•ì‹ í™•ì¸" ìš”ì²­ ê¸ˆì§€
3. ê²€ì¦ ê²°ê³¼ê°€ contextì— ìˆìœ¼ë©´ ê·¸ê±¸ ë°”íƒ•ìœ¼ë¡œ ë°”ë¡œ ë‹µë³€
4. ì‹¤ì œ ë°ì´í„° ê°’ ì–¸ê¸‰ ì‹œ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ (ì˜ˆ: ì‚¬ì›ë²ˆí˜¸ ì• 4ìë¦¬ë§Œ)

When answering questions about the system, refer to this knowledge base."""

    user_content = req.message.strip()
    if req.context and not has_context:
        user_content += f"\n\nContext: {json.dumps(req.context, ensure_ascii=False)}"

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content},
    ]


@router.post("/ask")
async def ask_agent(req: AgentAskRequest) -> Dict[str, Any]:
    if not req.message or not req.message.strip():
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="message is required")

    try:
        client = get_llm_client()
    except ValueError as e:
        # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ì¹œì ˆí•œ ë©”ì‹œì§€ ë°˜í™˜
        return {
            "answer": "âš ï¸ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n\nì„¤ì • ë°©ë²•:\n1. `.env` íŒŒì¼ì— `OPENAI_API_KEY=sk-...` ì¶”ê°€\n2. ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •\n\ní˜„ì¬ëŠ” AI ì—†ì´ ê¸°ë³¸ ê²€ì¦ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            "provider": "none",
            "used_tools": [],
            "error": "no_api_key"
        }
    
    try:
        messages = _build_messages(req)

        # 1ì°¨ LLM í˜¸ì¶œ (íˆ´ ì‚¬ìš© ê°€ëŠ¥)
        response = client.chat_with_tools(messages, AGENT_TOOLS)

        # íˆ´ í˜¸ì¶œì´ ìˆìœ¼ë©´ ì‹¤í–‰ í›„ 2ì°¨ í˜¸ì¶œ
        tool_calls = response.get("tool_calls", [])
        if tool_calls:
            # íˆ´ ì‹¤í–‰
            for tool_call in tool_calls:
                tool_name = tool_call["function"]["name"]
                arguments = json.loads(tool_call["function"]["arguments"])
                tool_result = _execute_tool(tool_name, arguments)

                # íˆ´ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                messages.append({"role": "assistant", "content": None, "tool_calls": [tool_call]})
                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "name": tool_name,
                        "content": json.dumps(tool_result, ensure_ascii=False),
                    }
                )

            # 2ì°¨ LLM í˜¸ì¶œ (íˆ´ ê²°ê³¼ í¬í•¨)
            final_response = client.chat_with_tools(messages, AGENT_TOOLS)
            answer = final_response.get("content", "")
        else:
            answer = response.get("content", "")

        # ììœ¨ í•™ìŠµ: ëŒ€í™” ë‚´ìš© ë¶„ì„í•˜ì—¬ í•™ìŠµ ê¸°íšŒ ê°ì§€
        try:
            validation_context = req.context.get("validation_results") if req.context else None
            analyze_chat_for_learning(req.message, answer, validation_context)
        except Exception as learn_err:
            # í•™ìŠµ ì‹¤íŒ¨í•´ë„ ì‘ë‹µì€ ì •ìƒì ìœ¼ë¡œ ë°˜í™˜
            logger.warning(f"Autonomous Learning ë¶„ì„ ì‹¤íŒ¨: {learn_err}")

        return {
            "answer": answer,
            "provider": client.provider,
            "used_tools": [tc["function"]["name"] for tc in tool_calls],
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"agent error: {str(e)}")


# ============================================
# /chat ì—”ë“œí¬ì¸íŠ¸ - SheetEditor AI ì±—ë´‡ìš©
# ============================================

class ChatRequest(BaseModel):
    message: str
    context: Optional[str] = None


@router.post("/chat", summary="SheetEditor AI ì±—ë´‡")
async def chat_with_ai(req: ChatRequest):
    """
    SheetEditorì˜ AI ì±—ë´‡ìš© ê°„ë‹¨í•œ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸.
    ì‚¬ìš©ìê°€ "ìˆ˜ì •í•´ì¤˜"ë¼ê³  í•˜ë©´ [ìˆ˜ì •:í–‰:í•„ë“œ:ê°’] í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ.
    """
    client = get_llm_client()
    
    system_prompt = """ë‹¹ì‹ ì€ HR ë°ì´í„° ìˆ˜ì • AIì…ë‹ˆë‹¤.

[ì ˆëŒ€ ê·œì¹™ - ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•¨]
ìˆ˜ì • ìš”ì²­ ì‹œ ì‘ë‹µì— ë°˜ë“œì‹œ ì´ í˜•ì‹ í¬í•¨: [ìˆ˜ì •:í–‰ë²ˆí˜¸:í•„ë“œëª…:ìƒˆê°’]

ì˜ˆì‹œ:
- ì‚¬ìš©ì: "1ë²ˆ 2024ë…„ 1ì›” 1ì¼ë¡œ ìˆ˜ì •"
- ì‘ë‹µ: 1ë²ˆ í•­ëª©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤. [ìˆ˜ì •:15:ì…ì‚¬ì¼ì:2024-01-01]

ê°’ ë³€í™˜:
- ë‚ ì§œ: YYYY-MM-DD (2024ë…„ 1ì›” 1ì¼ â†’ 2024-01-01)
- ê¸ˆì•¡: ìˆ«ìë§Œ (206ë§Œì› â†’ 2060000)

[ìˆ˜ì •:í–‰:í•„ë“œ:ê°’] ì—†ì´ ì‘ë‹µí•˜ë©´ ìˆ˜ì •ì´ ì ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤!
"""
    
    messages = [
        {"role": "system", "content": system_prompt},
    ]
    
    if req.context:
        messages.append({"role": "system", "content": f"[ì»¨í…ìŠ¤íŠ¸]\n{req.context}"})
    
    messages.append({"role": "user", "content": req.message})
    
    try:
        response = client.chat(messages)
        answer = response.get("content", "") if isinstance(response, dict) else str(response)
        
        return {"response": answer}
    except Exception as e:
        logger.error(f"Chat error: {e}")
        return {"response": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}
