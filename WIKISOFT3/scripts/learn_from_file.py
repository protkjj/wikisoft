#!/usr/bin/env python3
"""
íŒŒì¼ì—ì„œ í•™ìŠµ: ê²€ì¦ í›„ ì¼€ì´ìŠ¤ë¡œ ì €ì¥

ì‚¬ìš©ë²•:
    python scripts/learn_from_file.py <íŒŒì¼ê²½ë¡œ>
    python scripts/learn_from_file.py --all  # test_files í´ë” ì „ì²´
"""

import sys
import os

# WIKISOFT3 ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from pathlib import Path
import pandas as pd
from internal.parsers.parser import parse_roster
from internal.ai.matcher import match_headers
from internal.validators.validation_layer1 import validate_layer1
from internal.agent.confidence import estimate_confidence, detect_anomalies
from internal.memory.case_store import CaseStore


def parsed_to_dataframe(parsed: dict) -> pd.DataFrame:
    """parsed dictë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜."""
    headers = parsed.get("headers", [])
    rows = parsed.get("rows", [])
    return pd.DataFrame(rows, columns=headers)


def learn_from_file(file_path: str, auto_approve: bool = True):
    """
    íŒŒì¼ì—ì„œ í•™ìŠµí•˜ì—¬ ì¼€ì´ìŠ¤ë¡œ ì €ì¥.
    
    Args:
        file_path: Excel/CSV íŒŒì¼ ê²½ë¡œ
        auto_approve: ìë™ ìŠ¹ì¸ ì—¬ë¶€ (Trueë©´ ì‚¬ëŒ ê²€í†  ì—†ì´ ì €ì¥)
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“š í•™ìŠµ ì‹œì‘: {Path(file_path).name}")
    print(f"{'='*60}")
    
    # 1. íŒŒì¼ ì½ê¸°
    with open(file_path, "rb") as f:
        file_bytes = f.read()
    
    # 2. íŒŒì‹±
    print("\n[1/5] íŒŒì‹± ì¤‘...")
    parsed = parse_roster(file_bytes)
    headers = parsed.get("headers", [])
    row_count = len(parsed.get("rows", []))
    print(f"    âœ… í—¤ë”: {len(headers)}ê°œ, í–‰: {row_count}ê°œ")
    print(f"    ğŸ“‹ í—¤ë”: {headers[:5]}{'...' if len(headers) > 5 else ''}")
    
    # 3. í—¤ë” ë§¤ì¹­
    print("\n[2/5] í—¤ë” ë§¤ì¹­ ì¤‘...")
    matches_result = match_headers(parsed)  # parsed dict ì „ë‹¬
    matches = matches_result.get("matches", [])
    used_ai = matches_result.get("used_ai", False)
    print(f"    âœ… ë§¤ì¹­: {len(matches)}ê°œ, AI ì‚¬ìš©: {used_ai}")
    
    # ë§¤ì¹­ ê²°ê³¼ ìƒì„¸
    mapped = [m for m in matches if m.get("target") and not m.get("unmapped")]
    unmapped = [m for m in matches if m.get("unmapped") or not m.get("target")]
    low_conf = [m for m in matches if m.get("target") and m.get("confidence", 0) < 0.7]
    
    print(f"    ğŸ“Š ë§¤í•‘ë¨: {len(mapped)}, ë¯¸ë§¤í•‘: {len(unmapped)}, ë‚®ì€ ì‹ ë¢°ë„: {len(low_conf)}")
    
    if unmapped:
        print(f"    âš ï¸ ë¯¸ë§¤í•‘: {[m['source'] for m in unmapped[:5]]}")
    
    if low_conf:
        print(f"    âš ï¸ ë‚®ì€ ì‹ ë¢°ë„:")
        for m in low_conf[:3]:
            print(f"       - {m['source']} â†’ {m['target']} ({m['confidence']:.0%})")
    
    # 4. ê²€ì¦
    print("\n[3/5] L1 ê²€ì¦ ì¤‘...")
    df = parsed_to_dataframe(parsed)
    validation = validate_layer1(df, {})  # diagnostic_answersëŠ” ë¹ˆ dict
    errors = validation.get("errors", [])
    warnings = validation.get("warnings", [])
    print(f"    âœ… ì—ëŸ¬: {len(errors)}ê°œ, ê²½ê³ : {len(warnings)}ê°œ")
    
    # 5. ì‹ ë¢°ë„ ê³„ì‚°
    print("\n[4/5] ì‹ ë¢°ë„ ê³„ì‚° ì¤‘...")
    confidence = estimate_confidence(parsed, matches_result, validation)
    anomalies = detect_anomalies(parsed, matches_result, validation)
    
    conf_score = confidence.get("score", 0)
    print(f"    âœ… ì‹ ë¢°ë„: {conf_score:.1%}")
    print(f"    ğŸ“Š ìš”ì¸: {confidence.get('factors', {})}")
    
    if anomalies.get("detected"):
        print(f"    âš ï¸ ì´ìƒ íƒì§€: {len(anomalies.get('anomalies', []))}ê°œ")
        for a in anomalies.get("anomalies", []):
            print(f"       - [{a['severity']}] {a['message']}")
    
    # 6. ì¼€ì´ìŠ¤ ì €ì¥
    print("\n[5/5] ì¼€ì´ìŠ¤ ì €ì¥ ì¤‘...")
    store = CaseStore()
    
    # íŒŒì¼ëª…ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ
    filename = Path(file_path).name
    company_name = filename.split("_")[1] if "_" in filename else filename
    
    case_id = store.save_case(
        headers=headers,
        matches=matches,
        confidence=conf_score,
        was_auto_approved=auto_approve,
        human_corrections=None,  # ë‚˜ì¤‘ì— ìˆ˜ë™ ìˆ˜ì • ì‹œ ì—…ë°ì´íŠ¸
        metadata={
            "filename": filename,
            "company_name": company_name,
            "row_count": row_count,
            "error_count": len(errors),
            "warning_count": len(warnings),
            "anomaly_count": len(anomalies.get("anomalies", [])),
        }
    )
    
    print(f"    âœ… ì €ì¥ ì™„ë£Œ: case_id={case_id}")
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print(f"ğŸ“Š í•™ìŠµ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*60}")
    print(f"  íšŒì‚¬ëª…: {company_name}")
    print(f"  í—¤ë”: {len(headers)}ê°œ")
    print(f"  ë§¤í•‘ ì„±ê³µë¥ : {len(mapped)/len(matches)*100:.1f}%" if matches else "  ë§¤í•‘: N/A")
    print(f"  ì‹ ë¢°ë„: {conf_score:.1%}")
    print(f"  ìë™ ìŠ¹ì¸: {'ì˜ˆ' if auto_approve else 'ì•„ë‹ˆì˜¤'}")
    print(f"  ì¼€ì´ìŠ¤ ID: {case_id}")
    
    # í†µê³„ ì¶œë ¥
    stats = store.index.get("stats", {})
    print(f"\nğŸ“ˆ ì „ì²´ í†µê³„:")
    print(f"  ì´ ì¼€ì´ìŠ¤: {stats.get('total_cases', 0)}ê°œ")
    print(f"  ìë™ ìŠ¹ì¸: {stats.get('auto_approved', 0)}ê°œ")
    print(f"  ìˆ˜ë™ ìˆ˜ì •: {stats.get('manual_corrected', 0)}ê°œ")
    
    return {
        "case_id": case_id,
        "confidence": conf_score,
        "headers": len(headers),
        "mapped": len(mapped),
        "unmapped": len(unmapped),
    }


def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python scripts/learn_from_file.py <íŒŒì¼ê²½ë¡œ>")
        print("        python scripts/learn_from_file.py --all")
        sys.exit(1)
    
    if sys.argv[1] == "--all":
        # test_files í´ë” ì „ì²´ í•™ìŠµ
        test_dir = Path(__file__).parent.parent / "test_files"
        files = list(test_dir.glob("*.xls*")) + list(test_dir.glob("*.csv"))
        
        print(f"\nğŸ—‚ï¸ {len(files)}ê°œ íŒŒì¼ í•™ìŠµ ì‹œì‘")
        
        results = []
        for file_path in files:
            try:
                result = learn_from_file(str(file_path))
                results.append(result)
            except Exception as e:
                print(f"âŒ ì‹¤íŒ¨: {file_path.name} - {e}")
        
        print(f"\nâœ… ì™„ë£Œ: {len(results)}/{len(files)}ê°œ íŒŒì¼ í•™ìŠµë¨")
    else:
        # ë‹¨ì¼ íŒŒì¼ í•™ìŠµ
        file_path = sys.argv[1]
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            sys.exit(1)
        
        learn_from_file(file_path)


if __name__ == "__main__":
    main()
