"""
ê¸°ì¡´ ë°ì´í„° íŒŒì¼ì—ì„œ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ê·œì¹™ì„ í•™ìŠµí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.
"""
import os
import sys
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from internal.ai.knowledge_base import add_error_rule, learn_from_correction, load_error_rules
from internal.parsers.parser import parse_roster
from internal.ai.matcher import match_headers


def analyze_file(file_path: str) -> Dict[str, Any]:
    """íŒŒì¼ ë¶„ì„í•´ì„œ ë°ì´í„° íŒ¨í„´ ì¶”ì¶œ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‚ ë¶„ì„ ì¤‘: {os.path.basename(file_path)}")
    print('='*60)
    
    with open(file_path, 'rb') as f:
        file_bytes = f.read()
    
    # íŒŒì‹±
    parsed = parse_roster(file_bytes)
    headers = parsed.get("headers", [])
    rows = parsed.get("rows", [])
    
    print(f"  í–‰ ìˆ˜: {len(rows)}, ì»¬ëŸ¼ ìˆ˜: {len(headers)}")
    
    if not rows:
        return {"status": "empty"}
    
    # ë§¤ì¹­
    matches = match_headers(parsed, sheet_type="ì¬ì§ì")
    match_list = matches.get("matches", [])
    
    # ë§¤í•‘ êµ¬ì„±
    mapping = {}
    for m in match_list:
        if m.get("target"):
            mapping[m["source"]] = m["target"]
    
    print(f"  ë§¤í•‘ëœ ì»¬ëŸ¼: {len(mapping)}ê°œ")
    
    # DataFrame ìƒì„±
    df = pd.DataFrame(rows, columns=headers)
    
    # í‘œì¤€ ì»¬ëŸ¼ ì¶”ê°€
    for orig, std in mapping.items():
        if orig in df.columns:
            df[std] = df[orig]
    
    patterns = {
        "filename": os.path.basename(file_path),
        "row_count": len(rows),
        "mapped_columns": list(mapping.keys()),
        "statistics": {},
        "detected_patterns": []
    }
    
    # ê° í•„ë“œë³„ í†µê³„ ë¶„ì„
    for std_col in ["ìƒë…„ì›”ì¼", "ì…ì‚¬ì¼ì", "ê¸°ì¤€ê¸‰ì—¬", "ì„±ë³„", "ì¢…ì—…ì›êµ¬ë¶„"]:
        if std_col not in df.columns:
            continue
            
        col_data = df[std_col].dropna()
        if len(col_data) == 0:
            continue
        
        stats = {"field": std_col, "count": len(col_data)}
        
        # ìƒë…„ì›”ì¼ ë¶„ì„
        if std_col == "ìƒë…„ì›”ì¼":
            try:
                # ìˆ«ìí˜• ì—°ë„ ì¶”ì¶œ ì‹œë„
                years = []
                for val in col_data:
                    try:
                        if isinstance(val, (int, float)) and val > 10000:
                            # Excel ë‚ ì§œ ë˜ëŠ” YYYYMMDD
                            year = int(str(int(val))[:4])
                            if 1900 <= year <= 2100:
                                years.append(year)
                        elif isinstance(val, str) and len(val) >= 4:
                            year = int(val[:4])
                            if 1900 <= year <= 2100:
                                years.append(year)
                    except:
                        pass
                
                if years:
                    min_year = min(years)
                    max_year = max(years)
                    stats["min_year"] = min_year
                    stats["max_year"] = max_year
                    stats["age_range"] = f"{2026 - max_year}ì„¸ ~ {2026 - min_year}ì„¸"
                    print(f"  ğŸ“… {std_col}: {min_year}ë…„ ~ {max_year}ë…„ ({stats['age_range']})")
                    
                    # íŒ¨í„´ ê¸°ë¡
                    if min_year < 1945:
                        patterns["detected_patterns"].append({
                            "type": "age_range",
                            "field": "ìƒë…„ì›”ì¼",
                            "observation": f"ìµœê³ ë ¹ {2026-min_year}ì„¸ ì¡´ì¬",
                            "min_year": min_year
                        })
            except Exception as e:
                print(f"    âš ï¸ ìƒë…„ì›”ì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ê¸°ì¤€ê¸‰ì—¬ ë¶„ì„
        elif std_col == "ê¸°ì¤€ê¸‰ì—¬":
            try:
                salaries = pd.to_numeric(col_data, errors='coerce').dropna()
                if len(salaries) > 0:
                    min_sal = salaries.min()
                    max_sal = salaries.max()
                    avg_sal = salaries.mean()
                    stats["min"] = float(min_sal)
                    stats["max"] = float(max_sal)
                    stats["avg"] = float(avg_sal)
                    print(f"  ğŸ’° {std_col}: {min_sal:,.0f}ì› ~ {max_sal:,.0f}ì› (í‰ê· : {avg_sal:,.0f}ì›)")
                    
                    # íŒ¨í„´ ê¸°ë¡
                    if min_sal < 1900000 and min_sal > 0:
                        patterns["detected_patterns"].append({
                            "type": "salary_range",
                            "field": "ê¸°ì¤€ê¸‰ì—¬",
                            "observation": f"ìµœì €ì„ê¸ˆ ë¯¸ë‹¬ ê¸‰ì—¬ ì¡´ì¬ ({min_sal:,.0f}ì›)",
                            "min_salary": float(min_sal)
                        })
            except Exception as e:
                print(f"    âš ï¸ ê¸°ì¤€ê¸‰ì—¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ì„±ë³„ ë¶„ì„
        elif std_col == "ì„±ë³„":
            try:
                unique_vals = col_data.unique()
                stats["unique_values"] = [str(v) for v in unique_vals]
                print(f"  ğŸ‘¥ {std_col}: {unique_vals}")
            except:
                pass
        
        # ì¢…ì—…ì›êµ¬ë¶„ ë¶„ì„
        elif std_col == "ì¢…ì—…ì›êµ¬ë¶„":
            try:
                value_counts = col_data.value_counts().to_dict()
                stats["distribution"] = {str(k): int(v) for k, v in value_counts.items()}
                print(f"  ğŸ‘” {std_col}: {value_counts}")
            except:
                pass
        
        patterns["statistics"][std_col] = stats
    
    return patterns


def learn_patterns_from_analysis(all_patterns: List[Dict]) -> int:
    """ë¶„ì„ ê²°ê³¼ì—ì„œ ê·œì¹™ í•™ìŠµ"""
    learned_count = 0
    
    # 1. ê¸‰ì—¬ ë²”ìœ„ íŒ¨í„´ í•™ìŠµ
    salary_mins = []
    for p in all_patterns:
        if "ê¸°ì¤€ê¸‰ì—¬" in p.get("statistics", {}):
            stats = p["statistics"]["ê¸°ì¤€ê¸‰ì—¬"]
            if "min" in stats and stats["min"] > 0:
                salary_mins.append(stats["min"])
    
    if salary_mins:
        actual_min = min(salary_mins)
        if actual_min < 1900000:
            # ì‹¤ì œ ë°ì´í„°ì— ìµœì €ì„ê¸ˆ ë¯¸ë‹¬ ê¸‰ì—¬ê°€ ìˆìœ¼ë©´, ì´ëŠ” ê³„ì•½ì§/íŒŒíŠ¸íƒ€ì„ì¼ ê°€ëŠ¥ì„±
            learn_from_correction(
                field="ê¸°ì¤€ê¸‰ì—¬",
                original_value=str(int(actual_min)),
                was_error=True,
                correct_interpretation=f"ì‹¤ì œ ë°ì´í„°ì— {actual_min:,.0f}ì› ê¸‰ì—¬ ì¡´ì¬ - ê³„ì•½ì§/íŒŒíŠ¸íƒ€ì„ ê°€ëŠ¥ì„±",
                diagnostic_context={"ì‹¤ì œ_ìµœì €ê¸‰ì—¬": actual_min}
            )
            learned_count += 1
            print(f"\nâœ… í•™ìŠµ: ê¸°ì¤€ê¸‰ì—¬ {actual_min:,.0f}ì› íŒ¨í„´")
    
    # 2. ì—°ë ¹ ë²”ìœ„ íŒ¨í„´ í•™ìŠµ
    min_years = []
    for p in all_patterns:
        if "ìƒë…„ì›”ì¼" in p.get("statistics", {}):
            stats = p["statistics"]["ìƒë…„ì›”ì¼"]
            if "min_year" in stats:
                min_years.append(stats["min_year"])
    
    if min_years:
        oldest_year = min(min_years)
        oldest_age = 2026 - oldest_year
        if oldest_age > 75:
            learn_from_correction(
                field="ìƒë…„ì›”ì¼",
                original_value=str(oldest_year),
                was_error=True,
                correct_interpretation=f"ì‹¤ì œ ë°ì´í„°ì— {oldest_age}ì„¸ ì§ì› ì¡´ì¬ - ì„ì›/ê³ ë¬¸ ê°€ëŠ¥ì„±",
                diagnostic_context={"ì‹¤ì œ_ìµœê³ ë ¹": oldest_age}
            )
            learned_count += 1
            print(f"âœ… í•™ìŠµ: ìµœê³ ë ¹ {oldest_age}ì„¸ íŒ¨í„´")
    
    # 3. ì¢…ì—…ì›êµ¬ë¶„ ë¶„í¬ í•™ìŠµ
    emp_types = set()
    for p in all_patterns:
        if "ì¢…ì—…ì›êµ¬ë¶„" in p.get("statistics", {}):
            stats = p["statistics"]["ì¢…ì—…ì›êµ¬ë¶„"]
            if "distribution" in stats:
                emp_types.update(stats["distribution"].keys())
    
    if emp_types:
        print(f"\nğŸ“‹ ë°œê²¬ëœ ì¢…ì—…ì›êµ¬ë¶„: {emp_types}")
    
    return learned_count


def main():
    data_dir = "/Users/kj/Desktop/wiki/data"
    
    # í˜„ì¬ ê·œì¹™ ìˆ˜
    current_rules = load_error_rules()
    print(f"ğŸ“š í˜„ì¬ ê·œì¹™ ìˆ˜: {len(current_rules)}ê°œ")
    
    # ëª¨ë“  Excel íŒŒì¼ ë¶„ì„
    all_patterns = []
    
    for filename in os.listdir(data_dir):
        if filename.endswith(('.xls', '.xlsx')) and not filename.startswith('~'):
            file_path = os.path.join(data_dir, filename)
            try:
                patterns = analyze_file(file_path)
                if patterns.get("status") != "empty":
                    all_patterns.append(patterns)
            except Exception as e:
                print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ì´ {len(all_patterns)}ê°œ íŒŒì¼ ë¶„ì„ ì™„ë£Œ")
    print('='*60)
    
    # íŒ¨í„´ í•™ìŠµ
    learned = learn_patterns_from_analysis(all_patterns)
    
    # ê²°ê³¼ ìš”ì•½
    final_rules = load_error_rules()
    print(f"\nğŸ“š ìµœì¢… ê·œì¹™ ìˆ˜: {len(final_rules)}ê°œ (+{len(final_rules) - len(current_rules)})")
    print(f"âœ… í•™ìŠµëœ íŒ¨í„´: {learned}ê°œ")


if __name__ == "__main__":
    main()
